# enhanced_mask_detector.py - –ì–ò–ë–†–ò–î–ù–´–ô –î–ï–¢–ï–ö–¢–û–† –ú–ê–°–û–ö (Geometry + ML only)
# –£–ª—É—á—à–µ–Ω–∏—è:
#   ‚Ä¢ MediaPipe Face Detection –≤–º–µ—Å—Ç–æ Haar
#   ‚Ä¢ –ê–Ω–∞–ª–∏–∑ –¢–û–õ–¨–ö–û –Ω–∏–∂–Ω–µ–π —Ç—Ä–µ—Ç–∏ –ª–∏—Ü–∞ (–∫–∞–∫ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏)
#   ‚Ä¢ –í—Ö–æ–¥ –≤ –º–æ–¥–µ–ª—å —Å—Ç—Ä–æ–≥–æ –≤—ã—Ä–æ–≤–Ω–µ–Ω –ø–æ–¥ —Ç—Ä–µ–π–Ω (100√ó100, –Ω–∏–∂–Ω—è—è —Ç—Ä–µ—Ç—å ‚Üí –ø–∞–¥–¥–∏–Ω–≥)
#   ‚Ä¢ –£–±—Ä–∞–Ω–∞ —Ü–≤–µ—Ç–æ–≤–∞—è –ª–æ–≥–∏–∫–∞ ‚Äî —Ç–æ–ª—å–∫–æ ML

import cv2
import numpy as np
import joblib
import sys
import os
import warnings
from sklearn.exceptions import InconsistentVersionWarning
warnings.filterwarnings("ignore", category=InconsistentVersionWarning)

sys.path.append(os.path.dirname(__file__))

import mediapipe as mp
mp_face_mesh = mp.solutions.face_mesh  # ‚Üê –≠–¢–ê –°–¢–†–û–ö–ê –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–ê

# ===== MEDIAPIPE FACE DETECTION (lite, fast) =====
mp_face_detection = mp.solutions.face_detection

def calculate_head_coordinates(frame, face_center):
    h, w = frame.shape[:2]
    face_x = int(face_center[0] * w)
    face_y = int(face_center[1] * h)
    x1 = max(0, face_x - 120)
    y1 = max(0, face_y - 150)  # —á—É—Ç—å –±–æ–ª—å—à–µ –ø–æ –≤–µ—Ä—Ç–∏–∫–∞–ª–∏
    x2 = min(w, face_x + 120)
    y2 = min(h, face_y + 100)
    return face_x, face_y, x1, y1, x2, y2

def draw_skeleton(frame, landmarks, mp_drawing):
    connections = create_custom_connections()
    drawing_specs = (
        mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2, circle_radius=3),
        mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)
    )
    draw_custom_pose_landmarks(frame, landmarks, connections, drawing_specs)

def detect_faces_mp(roi, face_detector):
    """–¢–æ—á–Ω–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü –≤ ROI —á–µ—Ä–µ–∑ MediaPipe"""
    if roi.size == 0:
        return []
    rgb_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
    results = face_detector.process(rgb_roi)
    faces = []
    if results.detections:
        h_roi, w_roi = roi.shape[:2]
        for detection in results.detections:
            bbox = detection.location_data.relative_bounding_box
            if bbox:
                x = int(bbox.xmin * w_roi)
                y = int(bbox.ymin * h_roi)
                w = int(bbox.width * w_roi)
                h = int(bbox.height * h_roi)
                if w > 30 and h > 30:
                    faces.append((x, y, w, h))
    return faces

# üîë –¢–û–ñ–ï –°–ê–ú–û–ï, –ß–¢–û –í –¢–†–ï–ô–ù–ï! (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ!)
def extract_mask_features(face_roi):
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¢–û–ß–ù–û –ö–ê–ö –ü–†–ò –û–ë–£–ß–ï–ù–ò–ò.
    –ù–∞ –≤—Ö–æ–¥–µ: –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ ~100√ó100 (–ø—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ—Ç—Å—è, —á—Ç–æ —ç—Ç–æ –ª–∏—Ü–æ –∏–ª–∏ –µ–≥–æ –Ω–∏–∂–Ω—è—è —á–∞—Å—Ç—å).
    """
    face_roi_resized = cv2.resize(face_roi, (100, 100))
    h, w = face_roi_resized.shape[:2]

    # === –ö–õ–Æ–ß: –¢–û –ñ–ï –†–ê–ó–ë–ò–ï–ù–ò–ï, –ß–¢–û –í augment_train_improved_masks.py ===
    top_roi = face_roi_resized[:h//3, :]          # –≤–µ—Ä—Ö–Ω—è—è —Ç—Ä–µ—Ç—å ‚Äî –º–∞—Å–∫–∞ (–≤ —Ç—Ä–µ–π–Ω–µ —ç—Ç–æ top)
    middle_roi = face_roi_resized[h//3:2*h//3, :]
    bottom_roi = face_roi_resized[2*h//3:, :]     # –Ω–∏–∂–Ω—è—è —Ç—Ä–µ—Ç—å ‚Äî –ø–æ–¥–±–æ—Ä–æ–¥–æ–∫

    # –ì–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
    def get_hist(region, channels):
        hist = []
        for ch in channels:
            hch = cv2.calcHist([region], [ch], None, [12], [0, 256])
            hch = cv2.normalize(hch, hch).flatten()
            hist.append(hch)
        return np.hstack(hist)

    hist_top = get_hist(top_roi, [0, 1, 2])        # BGR
    hist_bottom = get_hist(bottom_roi, [0, 1, 2])  # BGR

    # HSV –¥–ª—è top
    hsv_top = cv2.cvtColor(top_roi, cv2.COLOR_BGR2HSV)
    hist_h = cv2.calcHist([hsv_top], [0], None, [10], [0, 180])
    hist_s = cv2.calcHist([hsv_top], [1], None, [10], [0, 256])
    hist_h = cv2.normalize(hist_h, hist_h).flatten()
    hist_s = cv2.normalize(hist_s, hist_s).flatten()

    # –°—Ä–µ–¥–Ω–∏–µ —Ü–≤–µ—Ç–∞
    avg_top = np.mean(top_roi, axis=(0, 1))
    avg_middle = np.mean(middle_roi, axis=(0, 1))
    avg_bottom = np.mean(bottom_roi, axis=(0, 1))

    # –†–∞–∑–Ω–∏—Ü—ã
    diff_tb = np.abs(avg_top - avg_bottom)
    diff_tm = np.abs(avg_top - avg_middle)
    diff_mb = np.abs(avg_middle - avg_bottom)

    # –¢–µ–∫—Å—Ç—É—Ä–∞
    gray = cv2.cvtColor(face_roi_resized, cv2.COLOR_BGR2GRAY)
    lap_var = np.var(cv2.Laplacian(gray, cv2.CV_64F))
    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    sobel_var = np.var(sobelx) + np.var(sobely)

    # –Ø—Ä–∫–æ—Å—Ç—å –∫–æ–Ω—Ç—Ä–∞—Å—Ç
    brightness_top = np.mean(gray[:h//3, :])
    brightness_bottom = np.mean(gray[2*h//3:, :])
    brightness_contrast = abs(brightness_top - brightness_bottom)

    # –°–±–æ—Ä–∫–∞
    features = np.hstack([
        hist_top, hist_bottom,
        hist_h, hist_s,
        avg_top, avg_middle, avg_bottom,
        diff_tb, diff_tm, diff_mb,
        [lap_var, sobel_var, brightness_contrast]
    ])
    return features.reshape(1, -1)

def prepare_lower_third_for_model(head_roi):
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –Ω–∏–∂–Ω—é—é —Ç—Ä–µ—Ç—å –≥–æ–ª–æ–≤—ã/–ª–∏—Ü–∞ –¥–ª—è –ø–æ–¥–∞—á–∏ –≤ –º–æ–¥–µ–ª—å.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (100, 100, 3) –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, —Å–æ–≤–º–µ—Å—Ç–∏–º–æ–µ —Å —Ç—Ä–µ–π–Ω–æ–º.
    """
    if head_roi.size == 0:
        return np.zeros((100, 100, 3), dtype=np.uint8)
    
    h, w = head_roi.shape[:2]
    # –ë–µ—Ä—ë–º –ù–ò–ñ–ù–Æ–Æ –¢–†–ï–¢–¨ (–≥–¥–µ —Ä–æ—Ç –∏ –ø–æ–¥–±–æ—Ä–æ–¥–æ–∫ ‚Äî –∑–æ–Ω–∞ –º–∞—Å–∫–∏!)
    lower_third = head_roi[2 * h // 3:, :]  # ~33% —Å–Ω–∏–∑—É
    
    if lower_third.size == 0:
        return np.zeros((100, 100, 3), dtype=np.uint8)
    
    # –†–µ—Å–∞–π–∑ –¥–æ –≤—ã—Å–æ—Ç—ã ~33, —à–∏—Ä–∏–Ω–∞ –ø—Ä–æ–ø–æ—Ä—Ü–∏–æ–Ω–∞–ª—å–Ω–∞
    target_h = 33
    scale = target_h / lower_third.shape[0]
    target_w = max(1, int(lower_third.shape[1] * scale))
    resized = cv2.resize(lower_third, (target_w, target_h), interpolation=cv2.INTER_AREA)
    
    # –ü–∞–¥–¥–∏–Ω–≥ –¥–æ 100√ó100 (–º–∞—Å–∫–∞ –≤–Ω–∏–∑—É, –∫–∞–∫ –Ω–∞ —Ç—Ä–µ–π–Ω–æ–≤—ã—Ö ROI)
    padded = np.zeros((100, 100, 3), dtype=np.uint8)
    y_offset = 100 - target_h  # –ø—Ä–∏–∂–∏–º–∞–µ–º –≤–Ω–∏–∑
    x_offset = max(0, (100 - target_w) // 2)
    x_end = min(100, x_offset + target_w)
    padded[y_offset:, x_offset:x_end] = resized[:, :x_end - x_offset]
    
    return padded

def draw_head_analysis(frame, x1_head, y1_head, x2_head, y2_head, head_roi, face_detector, mask_model):
    """
    –ß–ò–°–¢–´–ô ML-–ø–æ–¥—Ö–æ–¥:
      1. –ù–∞–π—Ç–∏ –ª–∏—Ü–∞ –≤ head ROI (MediaPipe –ø–æ—á—Ç–∏ –≤—Å–µ–≥–¥–∞ –Ω–∞—Ö–æ–¥–∏—Ç)
      2. –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞ ‚Äî –≤—ã—Ä–µ–∑–∞—Ç—å ‚Üí 100√ó100 ‚Üí predict
      3. –ù–∏–∫–∞–∫–∏—Ö fallback'–æ–≤, –Ω–∏–∫–∞–∫–∏—Ö "–µ—Å–ª–∏ –Ω–µ—Ç –ª–∏—Ü–∞"
    """
    faces = detect_faces_mp(head_roi, face_detector)

    if len(faces) == 0:
        # –†–µ–¥–∫–∏–π —Å–ª—É—á–∞–π ‚Äî —Ä–∏—Å—É–µ–º head bbox –∫–∞–∫ fallback
        cv2.rectangle(frame, (x1_head, y1_head), (x2_head, y2_head), (128, 128, 128), 2)
        cv2.putText(frame, "No face", (x1_head, y1_head - 10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        return

    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥–æ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –ª–∏—Ü–æ
    for (fx, fy, fw, fh) in faces:
        # –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        x1 = x1_head + fx
        y1 = y1_head + fy
        x2 = x1 + fw
        y2 = y1 + fh

        face_roi = frame[y1:y2, x1:x2]
        if face_roi.size == 0:
            continue

        try:
            #  –ö–õ–Æ–ß–ï–í–û–ô –ü–û–¢–û–ö:
            face_100 = cv2.resize(face_roi, (100, 100))      # –∫–∞–∫ –≤ —Ç—Ä–µ–π–Ω–µ
            features = extract_mask_features(face_100)       # –≤–∞—à–∞ —Ñ—É–Ω–∫—Ü–∏—è ‚Äî —Ç–æ—á–Ω–∞—è –∫–æ–ø–∏—è —Ç—Ä–µ–π–Ω–∞
            probas = mask_model.predict_proba(features)[0]
            pred = int(np.argmax(probas))
            conf = float(probas[pred])

            # –ö–ª–∞—Å—Å—ã
            labels = ['Mask OK', 'No Mask', 'Wrong Mask']
            colors = [(0, 255, 0), (0, 0, 255), (0, 165, 255)]

            label = labels[pred]
            color = colors[pred]

            # –û—Ç—Ä–∏—Å–æ–≤–∫–∞
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            text = f"{label} ({conf:.2f})"
            txt_color = (255, 255, 255) if np.mean(color) < 128 else (0, 0, 0)
            cv2.putText(frame, text, (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, txt_color, 2)

        except Exception as e:
            # –û—Ç–ª–∞–¥–∫–∞ –æ—à–∏–±–∫–∏ (–≤—Ä–µ–º–µ–Ω–Ω–æ)
            print(f" ML error: {e}")
            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 0), 2)
            cv2.putText(frame, "Error", (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

def draw_face_center(frame, face_x, face_y):
    cv2.circle(frame, (face_x, face_y), 5, (0, 0, 255), -1)

def main():
    print("===  MULTI-PERSON MASK DETECTOR (Face Mesh + ML) ===")
    print(" –ù–∞—Ç–∏–≤–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª–∏—Ü, –±–µ–∑ –¥—É–±–ª–µ–π")
    print("Press ESC to exit\n")

    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ ‚Äî –∫–∞–∫ —Ä–∞–Ω—å—à–µ
    mask_model = None
    model_name = None
    for model_path in [
        'mask_classifier_super_improved.pkl',
        'mask_classifier_fixed.pkl',
        'mask_classifier_augmented.pkl'
    ]:
        if os.path.exists(model_path):
            try:
                mask_model = joblib.load(model_path)
                model_name = model_path
                print(f" ML-–º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: '{model_name}'")
                break
            except Exception as e:
                print(f" –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ '{model_path}': {e}")
    if mask_model is None:
        print(" ML-–º–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
        return

    #  –ò–°–ü–û–õ–¨–ó–£–ï–ú FaceMesh —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ª–∏—Ü
    face_mesh = mp_face_mesh.FaceMesh(
        max_num_faces=5,                      # ‚Üê —Å–∫–æ–ª—å–∫–æ –ª–∏—Ü –º–∞–∫—Å–∏–º—É–º
        refine_landmarks=True,
        min_detection_confidence=0.5,
        min_tracking_confidence=0.5
    )
    print(" Face Mesh initialized (multi-face, no duplicates)")

    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print(" –ö–∞–º–µ—Ä–∞ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return

    print(" –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ü–∏–∏...")
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break

            #  –û–ë–ù–ê–†–£–ñ–ï–ù–ò–ï –í–°–ï–• –õ–ò–¶ –ó–ê –û–î–ò–ù –ü–†–û–•–û–î
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = face_mesh.process(rgb)

            all_faces = []
            if results.multi_face_landmarks:
                h, w = frame.shape[:2]
                for flm in results.multi_face_landmarks:
                    # –ü–æ–ª—É—á–∞–µ–º bbox –Ω–∞–ø—Ä—è–º—É—é –∏–∑ 468 —Ç–æ—á–µ–∫
                    xs = [lm.x for lm in flm.landmark]
                    ys = [lm.y for lm in flm.landmark]
                    x1 = int(min(xs) * w)
                    y1 = int(min(ys) * h)
                    x2 = int(max(xs) * w)
                    y2 = int(max(ys) * h)

                    # –î–æ–±–∞–≤–ª—è–µ–º padding (~10%)
                    pad_w = int(0.1 * (x2 - x1))
                    pad_h = int(0.1 * (y2 - y1))
                    x1 = max(0, x1 - pad_w)
                    y1 = max(0, y1 - pad_h)
                    x2 = min(w, x2 + pad_w)
                    y2 = min(h, y2 + pad_h)

                    all_faces.append((x1, y1, x2 - x1, y2 - y1))  # (x, y, w, h)

            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞ ‚Äî –∫–∞–∫ —Ä–∞–Ω—å—à–µ
            for (x, y, w_box, h_box) in all_faces:
                face_roi = frame[y:y+h_box, x:x+w_box]
                if face_roi.size == 0:
                    continue

                try:
                    face_100 = cv2.resize(face_roi, (100, 100))
                    features = extract_mask_features(face_100)
                    probas = mask_model.predict_proba(features)[0]
                    pred = int(np.argmax(probas))
                    conf = float(probas[pred])

                    labels = ['Mask OK', 'No Mask', 'Wrong Mask']
                    colors = [(0, 255, 0), (0, 0, 255), (0, 165, 255)]

                    label = labels[pred]
                    color = colors[pred]

                    cv2.rectangle(frame, (x, y), (x + w_box, y + h_box), color, 2)
                    text = f"{label} ({conf:.2f})"
                    txt_color = (255, 255, 255) if np.mean(color) < 128 else (0, 0, 0)
                    cv2.putText(frame, text, (x, y - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, txt_color, 2)

                except Exception as e:
                    print(f" ML error on face at ({x},{y}): {e}")
                    cv2.rectangle(frame, (x, y), (x + w_box, y + h_box), (255, 255, 0), 2)
                    cv2.putText(frame, "Error", (x, y - 10),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2)

            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            cv2.putText(frame, f"Faces: {len(all_faces)}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)

            cv2.imshow('Multi-Person Mask Detector', frame)
            if cv2.waitKey(1) & 0xFF == 27:
                break

    finally:
        cap.release()
        cv2.destroyAllWindows()
        face_mesh.close()
        print("\n –î–µ—Ç–µ–∫—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
        
if __name__ == "__main__":
    main()